[Pruning during training by network efficacy modeling | Semantic Scholar](https://www.semanticscholar.org/paper/Pruning-during-training-by-network-efficacy-Rajpal-Zhang/b6299ac4d2c0a3c179e34cb672dfd2e03b3bc3cb)

Deep neural networks (DNNs) are costly to train. Pruning, an approach to alleviate model complexity by zeroing out or pruning DNN elements, has shown promise in reducing training costs for DNNs with little to no efficacy at a given task. This paper presents a novel method to perform _early_ pruning of DNN elements (e.g., neurons or convolutional filters) _during the training process_ while minimizing losses to model performance. To achieve this, we model the efficacy of DNN elements in a Bayesian manner conditioned upon efficacy data collected during the training and prune DNN elements with low _predictive_ efficacy after training completion. Empirical evaluations show that the proposed Bayesian early pruning improves the computational efficiency of DNN training while better preserving model performance compared to other tested pruning approaches.